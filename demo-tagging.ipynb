{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Feed Auto Tagging using Random Forest Classifier\n",
    "\n",
    "This notebook demonstrates how to preprocess text data of news feed and train Random Forest Classifier to auto tag news feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Preprocessing\n",
    "\n",
    "First, let us load the data, preprocess the text data and split the data into training set and test set. For text preprocessing, we build our own stopword dictionary (specific for chinese characters) and perform some standard text cleaning procedures.\n",
    "\n",
    "* Remove HTML tag using BeautifulSoup\n",
    "* Remove all english letters, numbers, symbols using regular expression\n",
    "* Perform chinese word segmentation using Jeiba (a NLP library for chinese language)\n",
    "* Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"data/newsfeed.csv\",  header=0)\n",
    "X = df['text']\n",
    "y = df['tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stopwords(filepath):\n",
    "    '''\n",
    "    Load customized stopwords.txt\n",
    "    Return a dictionary of stopwords\n",
    "    '''\n",
    "    with open(filepath,'r') as file:\n",
    "        return set([line.strip() for line in file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text_array):\n",
    "    '''\n",
    "    Remove html tags, symbols, letters a-z A-Z, numbers\n",
    "    Perform chinese word segmentation\n",
    "    Remove stopwords \n",
    "    Return list of cleaned text\n",
    "    '''\n",
    "    cleaned_text_array = []\n",
    "    for i in range(len(text_array)):\n",
    "        raw_text = text_array[i]\n",
    "        cleaned_text = BeautifulSoup(raw_text, 'html5lib').get_text()  \n",
    "        chinese_only = re.sub('[0-9a-zA-Z\\xa0\\r\\n\\t\\u3000\\u2000-\\u206F\\u2E00-\\u2E7F\\!#$%&()*+,\\-.\\/:;<=>?@\\[\\]^_`{|}~]','',cleaned_text)\n",
    "        words = list(jieba.cut(chinese_only, cut_all=False))\n",
    "        words = [word for word in words if str(word) not in stopwords]\n",
    "        cleaned_text_array.append(' '.join(words))\n",
    "\n",
    "    return cleaned_text_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before text preprocessing:\n",
      "利物浦重賽擊敗乙組仔　英足盃過關 英格蘭足總盃第三圈今晨重賽，貴為英超勁旅的利物浦上場被乙組仔埃克斯特尷尬逼和，多獲一次機會的紅軍不敢再有差池。先有近期回勇的「威爾斯沙維」祖阿倫10分鐘開紀錄，加上兩個小將舒爾奧祖，及祖奧迪西拿下半場各入一球，以3比0擊敗對手，總算在主場挽 <p style=\"text-align: justify;\">英格蘭足總盃第三圈今晨重賽，貴為英超勁旅的利物浦上場被乙組仔埃克斯特尷尬逼和，多獲一次機會的紅軍不敢再有差池。先有近期回勇的「威爾斯沙維」祖阿倫10分鐘開紀錄，加上兩個小將舒爾奧祖，及祖奧迪西拿下半場各入一球，以3比0擊敗對手，總算在主場挽回面子，下一圈對手為韋斯咸。</p> <p style=\"text-align: justify;\">另一場英超球隊對壘，今季異軍突起的李斯特城戰至第三圈就宣告畢業。熱刺憑韓國前鋒孫興<U+615C>上半場遠射破網先開紀錄，換邊後此子助攻予中場查迪尼建功，令球隊以兩球輕取李斯特城，第四圈將面對英甲的高車士打。</p>\n",
      "\n",
      "After text preprocessing:\n",
      "利物浦 重賽 擊敗 乙組 仔英足 盃 過關   英格蘭足 總 盃 第三圈 今晨 重賽 貴為 英超 勁 旅 利物浦 上場 乙 組仔 埃克斯 特 尷尬 逼 多獲 一次 機會的紅 軍 不敢 再有 差池 先有 近期 回勇 威爾斯沙維 祖阿倫 分鐘 開紀錄 加上 兩個 小將 舒爾奧祖 及祖奧 迪西 拿下 半場 各入 一球 以比擊敗 對 手 總算 主場 挽   英格蘭足 總 盃 第三圈 今晨 重賽 貴為 英超 勁 旅 利物浦 上場 乙 組仔 埃克斯 特 尷尬 逼 多獲 一次 機會的紅 軍 不敢 再有 差池 先有 近期 回勇 威爾斯沙維 祖阿倫 分鐘 開紀錄 加上 兩個 小將 舒爾奧祖 及祖奧 迪西 拿下 半場 各入 一球 以比擊敗 對 手 總算 主場 挽回 面子 下 一圈 對手 為 韋斯咸   另 一場 英超球 隊 對 壘 今季異 軍 突起 李斯特 城戰 至 第三圈 宣告 畢業 熱刺 憑 韓國 前鋒 孫興 上半 場遠射 破 網先 開紀錄 換邊 後 此子 助攻 予中場 查迪尼 建功 令球隊 兩球 輕取 李斯特 城 第 四圈 將面 對 英甲 高車士 打\n"
     ]
    }
   ],
   "source": [
    "# build dictionary of stopwords from customized stopwords file\n",
    "stopwords = build_stopwords(filepath='data/stopwords.txt')\n",
    "\n",
    "# text preprocessing\n",
    "X_cleaned = clean_text(X)\n",
    "\n",
    "print('Before text preprocessing:')\n",
    "print(X[0])\n",
    "print('\\nAfter text preprocessing:')\n",
    "print(X_cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class labels:  ['梁振英', '美國大選', '足球']\n",
      "3115 training examples and 779 test cases\n",
      "\n",
      "Tag: 2 \n",
      "Text: 中超 足協 新政 引 地震 限上 名 外援 正選須 小將   為 提升 國內 足球 水平 中國足協 確不 遺餘力 今早 足協 更 宣布 年 新 措施 限制 外援 最多 上場 名人 次 而且 必須 至少 派 一名 小將 擔任 正選 英國 太陽報 指出 中國足協 相信 令 不少 歐洲球 會 鬆 一口 氣   今日 月 日 早上 中國足 協在 官網 發表名 為 中國足 協將 對 中 超中甲 聯賽 部分 相關 規程 內容 進行 調整 文章 表示 中超 中甲球會 聯席 工作 會議 上 中超 中甲 代表 中國足協 同意 調整 球季 中超 中甲 聯賽 規程 主要 內容 以下 兩點   今日 月 日 早上 中國足 協在 官網 發表名 為 中國足 協將 對 中 超中甲 聯賽 部分 相關 規程 內容 進行 調整 文章 表示 中超 中甲球會 聯席 工作 會議 上 中超 中甲 代表 中國足協 同意 調整 球季 中超 中甲 聯賽 規程 主要 內容 以下 兩點   太陽報 車路士 可 鬆 一口 氣 普遍 相信 今次 足協 新政 主要 眼見 中超 中甲球會 天價 買入 外援 卻 無助 提升 國家隊 水平 情況 希望 鼓勵 球會 多 起用 本土 球員 加強 青訓 不過 內 地 網民 擔心 新政 會令國 內球員 身價 暴漲 並打擊 球隊 引入 亞洲 外援 積極性 新政 亦 恐怕 危及 基藍馬 積施利 等 北 漂港將 位置 始終 港將 世界 級 外援 實力 一段 距離 另外 英國 太陽報 認為 中國足協 新政 下 車路士 主帥 干 地將 不用 擔心迪亞 高哥斯達 投 可 專心 爭奪 英超 冠 軍\n"
     ]
    }
   ],
   "source": [
    "# label encode the classes\n",
    "le = LabelEncoder()\n",
    "y_le = le.fit_transform(y)\n",
    "print('\\nClass labels: ', list(le.classes_))\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_le, test_size=0.2, random_state=0)\n",
    "print(\"{} training examples and {} test cases\".format(len(X_train), len(X_test)))\n",
    "\n",
    "print(\"\\nTag:\", y_train[0], \"\\nText:\", X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Bag of Words using TF-IDF\n",
    "\n",
    "We use `TfidfVectorizer()` from sklearn to convert a text into a numeric vector. In gist, tf-idf transformation counts word occurance frequency and normalizes by putting more weight on rare and meaningful words. After tf-idf transformation, each text is now represented by a feature vector of 1147 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in dictionary : 1147\n",
      "Example of words in dictionary : \n",
      " ['一份', '今日', '兼', '同時', '完場', '應', '方面', '比利', '相關', '自己', '較', '隊']\n"
     ]
    }
   ],
   "source": [
    "# create Bag of Words using tf-idf transform\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x.split(), lowercase=False, min_df=100) #minumum document frequency set to 100\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "print(\"Number of words in dictionary : {}\".format(len(tfidf.get_feature_names())))\n",
    "print(\"Example of words in dictionary : \\n\", tfidf.get_feature_names()[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3115, 1147)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Random Forest Classifier\n",
    "Next, we fit Random Forest Classifier on the training set using grid search on 10-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best paramenter set is: {'max_depth': None, 'n_estimators': 100}\n",
      "Mean test score:  [0.98812199 0.99165329 0.98298555 0.98844302 0.98619583 0.99133226]\n",
      "Std test score:  [0.00760298 0.00481237 0.00644868 0.00750141 0.00720326 0.00432309]\n"
     ]
    }
   ],
   "source": [
    "# grid search for best paramter set of random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "params = {\"max_depth\":[None, 10, 50],  #max depth of trees\n",
    "          \"n_estimators\":[10, 100]  #no. of tress to ensemble\n",
    "         } \n",
    "\n",
    "model = GridSearchCV(estimator=rf, param_grid=params, scoring='accuracy', cv=10, n_jobs=-1, verbose=0)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"\\nThe best paramenter set is:\", model.best_params_)\n",
    "print(\"Mean test score: \", model.cv_results_['mean_test_score'])\n",
    "print(\"Std test score: \", model.cv_results_['std_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate on Test Set\n",
    "\n",
    "Finally, we evaluate the model performance on the 20% test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9961489088575096\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       174\n",
      "          1       0.99      0.99      0.99       163\n",
      "          2       1.00      1.00      1.00       442\n",
      "\n",
      "avg / total       1.00      1.00      1.00       779\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make prediction on test set\n",
    "pred = model.predict(tfidf.transform(X_test))\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, pred))\n",
    "print('\\n', classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
